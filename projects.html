<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Amitabha Deb - Projects</title>
    <style>
        /* CSS Styling for Projects Page */
        body {
            font-family: Arial, sans-serif;
            margin: 0;
            padding: 0;
        }
        header {
            background-color: #333;
            color: #fff;
            padding: 20px;
            text-align: center;
        }
        nav {
            background-color: #333;
            text-align: center;
            padding: 10px 0;
        }
        nav a {
            color: white;
            text-decoration: none;
            padding: 14px 20px;
            display: inline-block;
        }
        nav a:hover {
            background-color: #555;
        }
        footer {
            background-color: #333;
            color: #fff;
            text-align: center;
            padding: 10px 0;
            position: fixed;
            bottom: 0;
            left: 0;
            width: 100%;
        }
        #projects {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 20px;
            padding: 20px;
        }
        .project-card {
            background-color: #f9f9f9;
            padding: 20px;
            border-radius: 5px;
            display: flex;
            flex-direction: column;
        }
        .thumbnail {
            max-width: 240px;
            height: auto;
            margin: 0 auto 10px;
            border-radius: 5px; /* Added border radius */
            display: block; /* Added display block */
        }
        .github-link {
            margin-top: auto;
            display: block; /* Display as block element */
            text-align: center; /* Center-align the link */
            font-weight: bold;
        }
        .github-link a {
            color: #4169E1;
            text-decoration: none;
            display: flex;
            align-items: center; /* Align icon and text vertically */
            justify-content: center; /* Align icon and text horizontally */
        }
        .github-link img {
            width: 40px; /* Doubled width */
            height: 40px; /* Doubled height */
            margin-right: 5px;
        }
    </style>



</head>
<body>
    <header>
        <h1>Amitabha Deb</h1>
    </header>
    <nav>
        <a href="index.html">About</a>
        <a href="education.html">Education</a>
        <a href="skills.html">Skills</a>
        <a href="projects.html">Projects</a>
        <a href="experience.html">Experience</a>
    </nav>
    <section id="projects">
        <!-- Include the content of your projects section here -->
        <div class="project-card">
            <div class="thumbnail">
                <img src="images/project1.png" alt="Project Thumbnail">
            </div>
            <h3>Utility of Image Enhancement For Underwater Tasks: GAN, YOLOv8, Siamese Network</h3>
            <p>Recently, learning-based image enhancement methods have demonstrated promising performance in underwater conditions. However, these models often come with a high computational cost. In this study, we aim to evaluate the relevance of image enhancement based on the specific task at hand. Additionally, we strive to develop a predictive method to determine whether image enhancement is necessary. Enhanced images were generated using ’Fast Underwater Image Enhancement for Improved Visual Perception’ (FUnIE- GAN) [1] and were evaluated quantitatively and visually. Further, bounding boxes were predicted using object detection models for both original and enhanced images. These predictions were analyzed and binary labels were created for the images to predict the necessity of image enhancement for the task. Despite our efforts, we have encountered challenges in devising an effective predictive method due to the limitations of the training set. This idea does show promise for further exploration with a specialized dataset to train all the models involved.</p>
            <div class="github-link">
                <a href="https://github.com/adeb567/ms-capstone" target="_blank">
                    <img src="images/github_icon.png" alt="GitHub">
                    GitHub Repository
                </a>
            </div>
        </div>
        <div class="project-card">
            <div class="thumbnail">
                <img src="images/project2.png" alt="Project Thumbnail">
            </div>
            <h3>Comparison of Reinforcement Learning Algorithms: Python, Dynamic Programming</h3>
            <p>Recently, learning-based image enhancement methods have demonstrated promising performance in underwater conditions. However, these models often come with a high computational cost. In this study, we aim to evaluate the relevance of image enhancement based on the specific task at hand. Additionally, we strive to develop a predictive method to determine whether image enhancement is necessary. Enhanced images were generated using ’Fast Underwater Image Enhancement for Improved Visual Perception’ (FUnIE- GAN) [1] and were evaluated quantitatively and visually. Further, bounding boxes were predicted using object detection models for both original and enhanced images. These predictions were analyzed and binary labels were created for the images to predict the necessity of image enhancement for the task. Despite our efforts, we have encountered challenges in devising an effective predictive method due to the limitations of the training set. This idea does show promise for further exploration with a specialized dataset to train all the models involved.</p>
            <div class="github-link">
                <a href="https://github.com/adeb567/reinforcemnet-learning-algorithms" target="_blank">
                    <img src="images/github_icon.png" alt="GitHub">
                    GitHub Repository
                </a>
            </div>
        </div>
        <div class="project-card">
            <div class="thumbnail">
                <img src="images/project3.png" alt="Project Thumbnail">
            </div>
            <h3>3D Semantic Reconstruction: PyTorch, Scikit-Learn, UNet, COLMAP, kNN Classifier</h3>
            <p>In this project, we conducted a 3D reconstruction of an environment while preserving the semantic information. We constructed a pipeline from 2D semantic labels and 3D reconstructed points to estimate 3D semantic reconstruction. Our methodology involves the generation of 3D sparse and dense point clouds using COLMAP, extraction of the segmentation masks using U-Net from the images provided, and finally employing a voting mechanism paired with a k-means algorithm to perform 3d semantic reconstruction.</p>
            <div class="github-link">
                <a href="https://github.com/adeb567/3d-Semantic-Reconstruction" target="_blank">
                    <img src="images/github_icon.png" alt="GitHub">
                    GitHub Repository
                </a>
            </div>
        </div>
        <div class="project-card">
            <div class="thumbnail">
                <img src="images/project4.png" alt="Project Thumbnail">
            </div>
            <h3>Off-road Driveable Area Segmentation: PyTorch, CycleGAN</h3>
            <p>In our project, we plan to employ CycleGAN as a pivotal tool for generating ground truth labels due to its unique ability to address the challenges associated with off-road data. CycleGAN facilitates the creation of synthetic off-road images and corresponding segmentation masks, effectively expanding the available dataset without the need for extensive manual labelling. By leveraging CycleGAN, we not only alleviate data scarcity issues but also enhance domain adaptation, making the segmentation model more robust to variations in off-road environments. This approach contributes to more costeffective and efficient data generation. It allows us to tackle the scarcity of labelled off-road data while ensuring the model’s capacity to perform effectively in a wide range of off-road scenarios.</p>
            <p>During the initial phase of our project, we focused on data exploration and understanding, as well as a comprehensive study of CycleGAN to ensure we have a solid grasp of its functioning and capabilities. This phase allowed us to identify specific dataset nuances and requirements unique to off-road scenarios. The dataset used is the ”Yamaha Off-Road Dataset” which has a lot of variability. In the later stages of the project, we shifted our attention to assessing the practical utility of the generated off-road images and segmentation masks. This evaluation involved rigorous testing of the model’s segmentation capabilities on an entirely unseen dataset, mimicking real-world scenarios that autonomous vehicles encounter. The goal is to measure the model’s generalization and ability to handle diverse off-road environments effectively. By carrying out these comprehensive testing procedures, we aim to validate the model’s robustness, thereby ensuring that it can reliably assist in off-road autonomous vehicle applications and contribute to the successful navigation of complex terrains.</p>
            <div class="github-link">
                <a href="https://github.com/adeb567/CSCI-5527-Project" target="_blank">
                    <img src="images/github_icon.png" alt="GitHub">
                    GitHub Repository
                </a>
            </div>
        </div>
      

        <div class="project-card">
            <h3>Web App for FUnIE-GAN, Deep-SESR, SVAM: Python, flask, HTML, and CSS</h3>
            <p>Created flask-based API and deployed the web app on the IRV lab server.</p>
        </div>
        <div class="project-card">
            <h3>Box Sorting using Baxter Robot: Robot Operating System (ROS), OpenCV, Computer Vision</h3>
            <p>Programmed Baxter robot to pick up color-coded boxes and place them on corresponding stacks.</p>
        </div>
        <div class="project-card">
            <h3>Generalizability of FLAN-T5 Model Using Composite Task Prompting: Hugging Face, LLM, NLP</h3>
            <p>Designed compositions of tasks to experiment with the generalizability of the model. Recognized the limitations caused by the prompt structure and several keywords.</p>
        </div>
        <div class="project-card">
            <h3>Mobile Robot Path Planning in Diverse Terrain Environments: Python, A*, D*, RRT</h3>
            <p>Evaluated the performance of search algorithms in a diverse 2d environment.</p>
        </div>
    </section>
    <footer>
        &copy; Amitabha Deb
    </footer>
</body>
</html>
