<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Amitabha Deb - Projects</title>
    <style>
        /* CSS Styling for Projects Page */
        body {
            font-family: Arial, sans-serif;
            margin: 0;
            padding: 0;
        }
        header {
            background-color: #333;
            color: #fff;
            padding: 20px;
            text-align: center;
        }
        nav {
            background-color: #333;
            text-align: center;
            padding: 10px 0;
        }
        nav a {
            color: white;
            text-decoration: none;
            padding: 14px 20px;
            display: inline-block;
        }
        nav a:hover {
            background-color: #555;
        }
        footer {
            background-color: #333;
            color: #fff;
            text-align: center;
            padding: 10px 0;
            position: fixed;
            bottom: 0;
            left: 0;
            width: 100%;
        }
        #projects {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 20px;
            padding: 20px;
        }
        .project-card {
            background-color: #f9f9f9;
            padding: 20px;
            border-radius: 5px;
            display: flex;
            flex-direction: column;
        }
        .thumbnail img {
            max-width: 240px;
            height: auto;
            margin: 0 auto 10px;
            border-radius: 5px; /* Added border radius */
            display: block; /* Added display block */
        }
        .github-link {
            margin-top: auto;
            text-align: center; /* Center-align the link */
            font-weight: bold;
        }
        .github-link a {
            color: #4169E1;
            text-decoration: none;
            display: flex;
            align-items: center; /* Align icon and text vertically */
            justify-content: center; /* Align icon and text horizontally */
        }
        .github-link img {
            width: 20px; /* Adjusted width */
            height: 20px; /* Adjusted height */
            margin-right: 5px;
        }
    </style>
</head>
<body>
    <header>
        <h1>Amitabha Deb</h1>
    </header>
    <nav>
        <a href="index.html">About</a>
        <a href="education.html">Education</a>
        <a href="skills.html">Skills</a>
        <a href="projects.html" style="font-size: 30px;">Projects</a>
        <a href="experience.html">Experience</a>
    </nav>
    <section id="projects">
        <!-- Include the content of your projects section here -->
        <div class="project-card">
            <div class="thumbnail">
                <img src="images/project1.png" alt="Project Thumbnail">
            </div>
            <h3>Utility of Image Enhancement For Underwater Tasks: GAN, YOLOv8, Siamese Network</h3>
            <p>Recently, learning-based image enhancement methods have demonstrated promising performance in underwater conditions. However, these models often come with a high computational cost. In this study, we aim to evaluate the relevance of image enhancement based on the specific task at hand. Additionally, we strive to develop a predictive method to determine whether image enhancement is necessary. Enhanced images were generated using ’Fast Underwater Image Enhancement for Improved Visual Perception’ (FUnIE- GAN) [1] and were evaluated quantitatively and visually. Further, bounding boxes were predicted using object detection models for both original and enhanced images. These predictions were analyzed and binary labels were created for the images to predict the necessity of image enhancement for the task. Despite our efforts, we have encountered challenges in devising an effective predictive method due to the limitations of the training set. This idea does show promise for further exploration with a specialized dataset to train all the models involved.</p>
            <div class="github-link">
                <a href="https://github.com/adeb567/ms-capstone" target="_blank">
                    <img src="images/github_icon.png" alt="GitHub">
                    GitHub Repository
                </a>
            </div>
        </div>
        <div class="project-card">
            <div class="thumbnail">
                <img src="images/project2.png" alt="Project Thumbnail">
            </div>
            <h3>Comparison of Reinforcement Learning Algorithms: Python, Dynamic Programming</h3>
            <p>Recently, learning-based image enhancement methods have demonstrated promising performance in underwater conditions. However, these models often come with a high computational cost. In this study, we aim to evaluate the relevance of image enhancement based on the specific task at hand. Additionally, we strive to develop a predictive method to determine whether image enhancement is necessary. Enhanced images were generated using ’Fast Underwater Image Enhancement for Improved Visual Perception’ (FUnIE- GAN) [1] and were evaluated quantitatively and visually. Further, bounding boxes were predicted using object detection models for both original and enhanced images. These predictions were analyzed and binary labels were created for the images to predict the necessity of image enhancement for the task. Despite our efforts, we have encountered challenges in devising an effective predictive method due to the limitations of the training set. This idea does show promise for further exploration with a specialized dataset to train all the models involved.</p>
            <div class="github-link">
                <a href="https://github.com/adeb567/reinforcemnet-learning-algorithms" target="_blank">
                    <img src="images/github_icon.png" alt="GitHub">
                    GitHub Repository
                </a>
            </div>
        </div>
        <div class="project-card">
            <div class="thumbnail">
                <img src="images/project3.png" alt="Project Thumbnail">
            </div>
            <h3>3D Semantic Reconstruction: PyTorch, Scikit-Learn, UNet, COLMAP, kNN Classifier</h3>
            <p>In this project, we conducted a 3D reconstruction of an environment while preserving the semantic information. We constructed a pipeline from 2D semantic labels and 3D reconstructed points to estimate 3D semantic reconstruction. Our methodology involves the generation of 3D sparse and dense point clouds using COLMAP, extraction of the segmentation masks using U-Net from the images provided, and finally employing a voting mechanism paired with a k-means algorithm to perform 3d semantic reconstruction.</p>
            <div class="github-link">
                <a href="https://github.com/adeb567/3d-Semantic-Reconstruction" target="_blank">
                    <img src="images/github_icon.png" alt="GitHub">
                    GitHub Repository
                </a>
            </div>
        </div>
        <div class="project-card">
            <div class="thumbnail">
                <img src="images/project4.png" alt="Project Thumbnail">
            </div>
            <h3>Off-road Driveable Area Segmentation: PyTorch, CycleGAN</h3>
            <p>In our project, we plan to employ CycleGAN as a pivotal tool for generating ground truth labels due to its unique ability to address the challenges associated with off-road data. CycleGAN facilitates the creation of synthetic off-road images and corresponding segmentation masks, effectively expanding the available dataset without the need for extensive manual labelling. By leveraging CycleGAN, we not only alleviate data scarcity issues but also enhance domain adaptation, making the segmentation model more robust to variations in off-road environments. This approach contributes to more costeffective and efficient data generation. It allows us to tackle the scarcity of labelled off-road data while ensuring the model’s capacity to perform effectively in a wide range of off-road scenarios.</p>
            <div class="github-link">
                <a href="https://github.com/adeb567/CSCI-5527-Project" target="_blank">
                    <img src="images/github_icon.png" alt="GitHub">
                    GitHub Repository
                </a>
            </div>
        </div>
        <div class="project-card">
            <div class="thumbnail">
                <img src="images/project5.png" alt="Project Thumbnail">
            </div>
            <h3>Web App for FUnIE-GAN, Deep-SESR, SVAM: Python, flask, HTML, and CSS</h3>
            <p>The image enhancement models often tend to have an overwhelming code base and is hard for people from other domains to access these models. For convenience and increased usage by people who want to use them for research and other applications, We have developed a flask-based app to easily interact with these models through the web and get the output. This lays down a platform to easily analyze the outputs of the model for future work.</p>
              <div class="github-link">
                <a href="https://github.com/adeb567/model-demos" target="_blank">
                    <img src="images/github_icon.png" alt="GitHub">
                    GitHub Repository
                </a>
            </div>
        </div>
        <div class="project-card">
            <div class="thumbnail">
                <img src="images/project6.png" alt="Project Thumbnail">
            </div>
            <h3>Box Sorting using Baxter Robot: Robot Operating System (ROS), OpenCV, Computer Vision</h3>
            <p>Robots have the potential to benefit us by increasing efficiency, reducing labour-intensive tasks, and allowing humans to focus on more complex and higher-value activities. Sorting objects at a large scale is an excellent example of this. In this project, we use Rethink Robotics’ Baxter robot with ROS and OpenCV to identify and sort boxes. We use object detection with colour recognition and inverse kinematics to accurately move the boxes. We achieved our goal of sorting and stacking cubes of three different colours. The work can be further extended to objects of multiple shapes and sizes.</p>
              <div class="github-link">
                <a href="https://github.com/adeb567/baxter_boxsort" target="_blank">
                    <img src="images/github_icon.png" alt="GitHub">
                    GitHub Repository
                </a>
            </div>
        </div>
        <div class="project-card">
            <div class="thumbnail">
                <img src="images/project7.png" alt="Project Thumbnail">
            </div>
            <h3>Generalizability of FLAN-T5 Model Using Composite Task Prompting: Hugging Face, LLM, NLP</h3>
            <p>This project aims to contribute to the field of natural language processing by evaluating the effectiveness of a widely used model "google/flan-t5" and exploring its potential for handling multiple tasks. We hope that the findings of this study will provide valuable insights and pave the way for further research in this area.</p>
              <div class="github-link">
                <a href="https://github.com/adeb567/CSCI5541-spring23-project" target="_blank">
                    <img src="images/github_icon.png" alt="GitHub">
                    GitHub Repository
                </a>
            </div>
        </div>
        <div class="project-card">
            <div class="thumbnail">
                <img src="images/project8.png" alt="Project Thumbnail">
            </div>
            <h3>Mobile Robot Path Planning in Diverse Terrain Environments: Python, A*, D*, RRT</h3>
            <p>Effective path planning is a crucial skill that these robots must possess to detect and make decisions based on various obstacles and topographical perturbations. In this project, two simple planning problems will be posed. The first problem will include robot path planning in an environment with only obstacles. This environment will be used to compare some more advanced pathplanning algorithms that build off of algorithms covered in class. The second problem will be determining an efficient method for path planning in an obstructed and uneven environment. Only A* will be used in this scenario and the diverse terrain will be represented by a custom cost map. Results from these two problems will highlight the advantages and disadvantages of more advanced search algorithms, and provide preliminary results for their operation in diverse terrain environments.</p>
              
        </div>
    </section>
    <footer>
        &copy; Amitabha Deb
    </footer>
</body>
</html>
